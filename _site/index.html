<!doctype html>
<html lang=" en-US">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title> Fairness Measures - Detecting Algorithmic Discrimination</title>

    <link rel="stylesheet"
          href="/assets/css/style.css?v=638069990a084005bd9f64127b5b8efbb7ab2e4c">
    <meta name="viewport" content="width=device-width">

    <meta name="keywords"
          content="algorithmic bias, algorithmic fairness, fairness benchmarking, dataset, machine learning, discrimination discovery"/>
    <meta name="description" content="A Fairness Benchmarking Tool for Machine Learning"/>
    <meta name="robots" content="index/follow">

</head>
<body>
    <div class="wrapper">
        <header>
            <h1><a href="http://localhost:4000">Fairness Measures</a></h1>
            <p>Datasets and Software for Detecting Algorithmic Discrimination</p>

            <menu style="list-style: none; padding: 0;
            list-style-type: none;">
                <p><a href="http://localhost:4000">Home</a></p>
                <p><a href="http://localhost:4000/Pages/Definitions">Definitions</a></p>
                <p><a href="http://localhost:4000/Pages/Ranking">Ranking Algorithms</a></p>
                <p><a href="http://localhost:4000/Pages/Classification">Classification Algorithms</a></p>
                <p><a href="http://localhost:4000/Pages/Datasets">Datasets</a></p>
                <p><a href="http://localhost:4000/Pages/Videos">Videos</a></p>
                <p><a href="https://github.com/FairnessMeasures/fairness-measures-code" target="_blank">Code (on
                GitHub)</a> &#128279;</p>
                <p><a href="http://localhost:4000/Pages/About">About</a></p>
            </menu>

        </header>
        <section>
            <img src="http://localhost:4000/Resources/Hero.svg" alt="Header">
            </br></br></br>

            <!-- http://www.tablesgenerator.com/markdown_tables# -->
<p>The risen prevalence of automated decision-making process is increasing the risk associated with models that can potentially discriminate against disadvantaged groups. The Fairness Measures Project contributes to the development of fairness-aware algorithms and systems by providing relevant datasets and software.</p>

<p>You may find here a series of <a href="/Pages/Datasets.html">datasets</a> we have collected and/or prepared. These datasets are from
various fields and applications (e.g., finance, law, and human resources). We also provide common <a href="/Pages/Definitions.html">fairness 
definitions in machine learning</a>. In addition, you can find a few fairness algorithms, both in the area of <a href="/Pages/Ranking.html">ranking</a> and <a href="/Pages/Classification.html">classification</a>.</p>

<p>We would love to hear your comments and suggestions, please contact <a href="mailto:meike.zehlike@tu-berlin.de?Subject=Fairness%20measures%20website">Meike Zehlike</a> for any feedback you may have.</p>

<p><br />
Help us spread the word: <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A//fairness-measures.org" target="_blank">Share on Facebook</a> | <a href="https://twitter.com/home?status=Fairness%20Measures%20project%20-%20http%3A//fairness-measures.org" target="_blank">Share on Twitter</a> | <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3A//fairness-measures.org&amp;title=Fairness%20Measures%20project&amp;summary=&amp;source=" target="_blank">Share on LinkedIn</a></p>

<!-- Ideas to complete Text with:

- certain to always get the best unbiased search result
- uncertainiity - isolated fact, no controversies
- Difference between:
    - knowleddge vs. information.
    - valuing thing differently, opinionated “what makes us human”
        - arguable / objective knowledge
- manipulate search result as a protest
- human evaluation as desplicable and honorable
- authority/power
- right/wrong - like, dislike
- coders are also biased
it is impertaive: humanities, technology
seductive idea, remains a myth


technology companies are applying censorship standards arbitrarily (old)
https://www.ted.com/talks/rebecca_mackinnon_let_s_take_back_the_internet#t-132377

- Keywords: advocacy, good governance,political innovation, consent of the network, open source code, statistical numbers (Kennzahlen),

Short Paragraphs (for those with a small attn. span). highlight keywords

-->


        </section>
        <footer>
            <p>
                <a href="http://www.upf.edu/"><img hspace="2" src="http://localhost:4000/Resources/upf_logo.png"
                        style="height: 30px; margin: 4px;" alt="UPF logo"></a>
                <a href="http://www.cit.tu-berlin.de"><img hspace="2" src="http://localhost:4000/Resources/tu_logo.png"
                        style="height: 30px; margin: 4px;" alt="TU Berlin logo"></a>
            </p>
            <!--
            <p>This project is maintained by <a href="https://github.com/MilkaLichtblau"> Meike Zehlike </a> and <a href="http://github.com/FairnessMeasures">Mohamed Megahed</a></p>
            -->
            <p>
                <small>All content available under a <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY-4.0 license</a> unless specified otherwise. 
                    <script>document.write(new Date().getFullYear())</script>
                </small>
            </p>
        </footer>
    </div>

    <script src="/assets/js/scale.fix.js"></script>



<script>
    (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
        a = s.createElement(o),
            m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-101054904-1', 'auto');
    ga('send', 'pageview');
</script>


</body>
</html> 